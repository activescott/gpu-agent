name: nvidia-geforce-rtx-4080
label: NVIDIA Geforce RTX 4080
tensorCoreCount: 304
fp32TFLOPS: 97.4
fp16TFLOPS: 398.8
int8TOPS: 779.82
memoryCapacityGB: 16
memoryBandwidthGBs: 716.8
maxTDPWatts: 320
gpuArchitecture: ada
supportedHardwareOperations:
  - FP16
  - INT8
  - TF32
  - INT4
  - BF16
  - FP8
supportedCUDAComputeCapability: 8.9
summary: |
  The NVIDIA GeForce RTX 4080 is a graphics card released in 2022,
  featuring the Ada Lovelace architecture based on the AD103 GPU. The set of
  retail cards in the NVIDIA RTX 40-series cards is RTX 4090, RTX 4080 SUPER,
  RTX 4080, RTX 4070 Ti SUPER, RTX 4070 Ti, RTX 4070 SUPER, RTX 4070, RTX 4060
  Ti, and the RTX 4060. The NVIDIA L40 GPU and L4 GPUs are also based on the
  same Ada Architecture aimed at the data center. While primarily aimed at
  gamers, the RTX 4080 also offers strong capabilities for machine learning
  tasks, particularly inference and training workloads that benefit from its
  large memory and high core count. It uses a PCI-Express 4.0 x16 host
  interface.
references:
  - https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf
  - https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf
  - https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/
  - https://lambdalabs.com/blog/nvidia-rtx-4090-vs-rtx-3090-deep-learning-benchmark
  - https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4090-out-now/

notes:
  - fp16TFLOPS is "Peak FP16 Tensor TFLOPS with FP16 Accumulate" as that's what NVIDIA publishes. Using the "with sparsity" metric.
  - int8TOPS of 1321.2 is "peak INT 8 TOPS" using "Effective TOPS / TFLOPS using the new Sparsity Feature". They also reveal it as 660.6 "based on GPU Boost Clock". This comes from the ada-gpu-architecture-whitepaper-v2.1.
  - Power based on what NVIDIA refers to as "TGP (Total Graphics Power)"
