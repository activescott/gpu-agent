# yaml-language-server: $schema=./gpu-spec.schema.json
name: nvidia-l4
label: NVIDIA L4
tensorCoreCount: 240
fp32TFLOPS: 120
fp16TFLOPS: 242
int8TOPS: 485
memoryCapacityGB: 24
memoryBandwidthGBs: 300
gpuArchitecture: ada
supportedHardwareOperations:
  - FP16
  - INT8
  - TF32
  - INT4
  - BF16
  - FP8
supportedCUDAComputeCapability: 8.9
summary: The NVIDIA L4 GPU was introduced in March 2023 with part number
  900-2G193-0000-000. It, along with the L40 are the NVIDIA Ada Lovelace
  architecture built using the Built on the 5 nm process. The L4 uses the AD104
  graphics processor, fourth-generation Tensor Cores, deep learning super
  sampling (DLSS 3) and 24 GB GDDR6 memory. The L4 is unique in that its maximum
  power draw is only 72 W which is quite low compared with other Tensor Core
  GPUs such as the such as the L40 at 300W and L40S at 350W. It is a single-slot
  PCIe 4.0 x16 card without connectivity for monitors.
maxTDPWatts: 72
references:
  - https://www.nvidia.com/en-us/data-center/l4/
  - https://nvdam.widen.net/s/rvq98gbwsw/l4-datasheet-2595652
  - https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf
  - https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units
  - https://www.techpowerup.com/gpu-specs/l4.c4091
  - https://www.nvidia.com/en-us/technologies/ada-architecture/
  - https://developer.nvidia.com/blog/supercharging-ai-video-and-ai-inference-performance-with-nvidia-l4-gpus/
