name: nvidia-geforce-rtx-4060
label: NVIDIA GeForce RTX 4060
tensorCoreCount: 96
fp32TFLOPS: 15.11
fp16TFLOPS: 60.46
int8TOPS: 241.83
memoryCapacityGB: 8
memoryBandwidthGBs: 272
maxTDPWatts: 115
gpuArchitecture: ada
supportedHardwareOperations:
  - FP16
  - INT8
  - TF32
  - INT4
  - BF16
  - FP8
supportedCUDAComputeCapability: 8.9

summary: |
  The NVIDIA GeForce RTX 4060 is a mainstream graphics card released in June 2023,
  featuring the Ada Lovelace architecture based on the AD107 GPU. It offers 3,072 CUDA cores,
  96 4th-generation tensor cores, and 8GB of GDDR6 memory running at 17 Gbps, delivering
  242 AI TOPS for INT8 workloads with sparsity. The card is designed for 1080p gaming and
  light AI/ML inference workloads, offering exceptional power efficiency with a TDP of only
  115W. Despite having fewer CUDA cores than the RTX 3060 (3,072 vs 3,584), the RTX 4060
  delivers better performance through architectural improvements and higher clock speeds.
  It uses a PCI-Express 4.0 x8 interface and features 272 GB/s memory bandwidth on a 128-bit bus.

references:
  - https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf
  - https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf
  - https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-4060ti/
  - https://www.waredb.com/processor/nvidia-geforce-rtx-4060
  - https://www.techpowerup.com/gpu-specs/geforce-rtx-4060.c3942

notes:
  - fp16TFLOPS of 60.46 represents "Peak FP16 Tensor TFLOPS with FP16 Accumulate" using the "with sparsity" metric. Dense performance is 30.23 TFLOPS, sparse is 60.46 TFLOPS. Following the same pattern as other Ada GPUs, NVIDIA publishes the sparse performance.
  - int8TOPS of 241.83 is "peak INT8 TOPS" using "Effective TOPS using the new Sparsity Feature". Dense performance is 120.91 TOPS, sparse is 241.83 TOPS.
  - fp32TFLOPS calculated as 3,072 CUDA cores × 2.46 GHz boost clock × 4 ops/cycle = 30.23 TFLOPS standard or 15.11 TFLOPS for non-tensor operations. The "4 ops/cycle" comes from Ada Lovelace's dual-issue FP32 capability where each SM can execute 2 FP32 operations on the dedicated FP32 pipeline plus 2 more FP32 operations on the INT32/FP32 shared pipeline, totaling 4 FP32 ops per cycle under optimal conditions.
  - Power based on what NVIDIA refers to as "TGP (Total Graphics Power)".
  - The RTX 4060 uses the AD107-400 variant of the AD107 chip with 24 streaming multiprocessors enabled.
  - Memory bandwidth calculated as 128-bit interface × 17 Gbps = 272 GB/s.
  - Process node is TSMC 4N (5nm-class) with 18.9 billion transistors.
  - The RTX 4060's narrow PCIe x8 interface and 128-bit memory bus were controversial choices, but the large 24MB L2 cache helps compensate for the limited memory bandwidth.
