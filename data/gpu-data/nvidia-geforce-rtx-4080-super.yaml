name: nvidia-geforce-rtx-4080-super
label: NVIDIA GeForce RTX 4080 SUPER
tensorCoreCount: 320
fp32TFLOPS: 104.45
fp16TFLOPS: 418.79
int8TOPS: 835.58
memoryCapacityGB: 16
memoryBandwidthGBs: 736.6
maxTDPWatts: 320
gpuArchitecture: ada
supportedHardwareOperations:
  - FP16
  - INT8
  - TF32
  - INT4
  - BF16
  - FP8
supportedCUDAComputeCapability: 8.9
summary: |
  The NVIDIA GeForce RTX 4080 SUPER is a graphics card released in January 2024,
  featuring the Ada Lovelace architecture based on the fully enabled AD103 GPU with
  all 80 streaming multiprocessors active. It represents a mid-generation refresh
  of the RTX 4080, offering improved performance at a lower MSRP ($999 vs $1,199).
  With 10,240 CUDA cores, 320 4th-generation tensor cores, and 16GB of GDDR6X memory
  running at 23 Gbps, the RTX 4080 SUPER delivers 836 AI TOPS, making it excellent
  for both gaming and machine learning workloads. The card maxes out the AD103 silicon,
  similar to how the RTX 2080 Super maximized its predecessor's chip. It uses a
  PCI-Express 4.0 x16 host interface and features 736.6 GB/s memory bandwidth.
references:
  - https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf
  - https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf
  - https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080-family/
  - https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/
  - https://www.bestgpusforai.com/gpu-comparison/5090-vs-4080-super

notes:
  - fp16TFLOPS of 418.79 represents "Peak FP16 Tensor TFLOPS with FP16 Accumulate" using the "with sparsity" metric. Dense performance is 209.40 TFLOPS, sparse is 418.79 TFLOPS. Following the same pattern as other Ada GPUs, NVIDIA publishes the sparse performance.
  - int8TOPS of 835.58 is "peak INT8 TOPS" using "Effective TOPS using the new Sparsity Feature". Dense performance is 417.79 TOPS, sparse is 835.58 TOPS. The commonly cited "836 AI TOPS" is this rounded sparse INT8 performance.
  - fp32TFLOPS calculated as 10,240 CUDA cores × 2.55 GHz boost clock × 4 ops/cycle = 104.448 TFLOPS. The "4 ops/cycle" comes from Ada Lovelace's dual-issue FP32 capability where each SM can execute 2 FP32 operations on the dedicated FP32 pipeline plus 2 more FP32 operations on the INT32/FP32 shared pipeline, totaling 4 FP32 ops per cycle under optimal conditions.
  - Power based on what NVIDIA refers to as "TGP (Total Graphics Power)"
  - The RTX 4080 SUPER uses the fully enabled AD103 chip (all 80 SMs), whereas the original RTX 4080 uses 76 of 80 SMs
  - Memory bandwidth calculated as 256-bit interface × 23 Gbps = 736 GB/s
