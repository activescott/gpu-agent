# Nvidia H100-SXM-80GB Machine Learning Accelerator

The Nvidia H100-SXM-80GB, launched on March 22nd, 2022, represents a significant leap in GPU technology. Built on a 4 nm process and utilizing the GH100 graphics processor, it offers exceptional computational power, especially with its 528 Tensor Cores tailored for accelerating machine learning applications. Its massive 80 GB HBM3 memory and astounding 3.35 TB/s memory bandwidth make it a powerhouse for demanding AI tasks, including both training and inference. The H100-SXM-80GB is a testament to Nvidia's commitment to advancing AI and machine learning capabilities, providing unparalleled performance for complex computational tasks.

## Specifications

- **GPU Architecture**: 4 nm process, GH100 graphics processor.
- **Memory Size**: 80 GB HBM3.
- **Memory Bandwidth**: 3.35 TB/s.
- **Tensor Cores**: 528.
- **GPU Clock Rate**: 1590 MHz (Base), 1980 MHz (Boost).
- **Max Power Consumption**: Up to 700W (configurable).
- **FP32 TFLOPS**: 67 teraFLOPs.

## References

- [NVIDIA's Official Website](https://www.nvidia.com/en-gb/data-center/h100/)
- [TechPowerUp GPU Database](https://www.techpowerup.com/gpu-specs/h100-sxm5-80-gb.c3900)
