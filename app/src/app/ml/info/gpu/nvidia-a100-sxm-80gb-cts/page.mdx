# NVIDIA A100-SXM-80GB CTS Machine Learning Accelerator

The NVIDIA A100-SXM-80GB CTS is a state-of-the-art accelerator designed primarily for deep learning training and high-performance computing. Launched in 2020, it showcases the NVIDIA Ampere architecture, boasting an impressive 80GB of HBM2e memory. Its significant memory bandwidth and tensor cores make it exceptionally suitable for AI and data analytics applications. The A100-SXM-80GB CTS stands out for its ability to handle massive workloads, offering unparalleled performance in large-scale AI environments. The custom thermal solution (CTS) SKU can support TDPs up to 500W.

## Specifications

- **GPU Architecture**: NVIDIA Ampere
- **Memory Size**: 80 GB HBM2e
- **Memory Bandwidth**: 1,935 GB/s
- **Tensor Cores**: 432
- **GPU Clock Rate**: Base clock 1275 MHz, Boost clock up to 1410 MHz
- **Max Power Consumption**: Up to 500 W (CTS version)
- **FP32 TFLOPS**: 19.5 TFLOPS

## References

- [TechPowerUp](https://www.techpowerup.com/gpu-specs/a100-pcie-80-gb.c3821))
- [NVIDIA](https://www.nvidia.com/en-us/data-center/a100/))
